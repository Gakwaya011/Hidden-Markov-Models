{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c349d71",
   "metadata": {},
   "source": [
    "# Unseen Data Evaluation\n",
    "This notebook loads the trained HMM and preprocessing pipeline, extracts features from a cleaned dataset CSV (preferring `testdata/test_data.csv` if present, otherwise `cleaned_data.csv`), runs predictions, and reports per-class sensitivity, specificity, and overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3062f0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded artifacts:\n",
      "{'scaler': 'StandardScaler', 'pca': 'PCA', 'hmm': 'GaussianHMM'}\n",
      "States: ['being_still', 'jumping', 'standing', 'walking']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "\n",
    "# Load model artifacts saved from training\n",
    "try:\n",
    "    import joblib\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'joblib', '-q'])\n",
    "    import joblib\n",
    "\n",
    "ARTIFACTS = Path('artifacts/model_bundle.joblib')\n",
    "if not ARTIFACTS.exists():\n",
    "    raise FileNotFoundError(\"artifacts/model_bundle.joblib not found. Open markov_model.ipynb and run the cell that saves artifacts.\")\n",
    "\n",
    "bundle = joblib.load(ARTIFACTS)\n",
    "scaler = bundle['scaler']\n",
    "pca = bundle.get('pca', None)\n",
    "hmm = bundle['hmm']\n",
    "STATES = bundle['STATES']\n",
    "STATE_TO_IDX = bundle['STATE_TO_IDX']\n",
    "IDX_TO_STATE = bundle['IDX_TO_STATE']\n",
    "FEATURE_COLS_TRAIN = bundle['FEATURE_COLS']\n",
    "window_seconds_default = bundle.get('window_seconds', 2.0)\n",
    "overlap_default = bundle.get('overlap', 0.5)\n",
    "\n",
    "print(\"Loaded artifacts:\")\n",
    "print({k: type(v).__name__ if hasattr(v, '__class__') else type(v) for k, v in bundle.items() if k in ['scaler','pca','hmm']})\n",
    "print(\"States:\", STATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c6fa8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config and label normalization\n",
    "\n",
    "activity_map = {\n",
    "    'being still': 'being_still',\n",
    "    'still': 'being_still',\n",
    "    'jump': 'jumping',\n",
    "    'jumping': 'jumping',\n",
    "    'stand': 'standing',\n",
    "    'standing': 'standing',\n",
    "    'walk': 'walking',\n",
    "    'walking': 'walking',\n",
    "}\n",
    "\n",
    "def normalize_activity(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    s = str(name).strip().lower()\n",
    "    return activity_map.get(s, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e77356e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction utilities (aligned with training)\n",
    "def compute_sampling_rate_hz(time_series: pd.Series) -> float:\n",
    "    dt = pd.Series(time_series).diff().dropna().median()\n",
    "    if dt is None or dt <= 0:\n",
    "        raise ValueError(\"Non-positive or undefined sampling interval detected in test data.\")\n",
    "    return 1.0 / dt\n",
    "\n",
    "ACC_COLUMNS = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "GYRO_COLUMNS = [\"gyro_x\", \"gyro_y\", \"gyro_z\"]\n",
    "SENSOR_COLUMNS = ACC_COLUMNS + GYRO_COLUMNS\n",
    "\n",
    "def generate_windows(df: pd.DataFrame, sampling_rate_hz: float, window_seconds: float, overlap: float):\n",
    "    window_samples = int(round(window_seconds * sampling_rate_hz))\n",
    "    if window_samples < 2:\n",
    "        raise ValueError(\"Increase window_seconds; not enough samples per window.\")\n",
    "    step_samples = max(1, int(round(window_samples * (1.0 - overlap))))\n",
    "    for activity, group in df.groupby(\"activity\", sort=False):\n",
    "        group = group.reset_index(drop=True)\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "        if len(group) <= window_samples:\n",
    "            yield activity, group.copy()\n",
    "            continue\n",
    "        for start in range(0, len(group) - window_samples + 1, step_samples):\n",
    "            end = start + window_samples\n",
    "            segment = group.iloc[start:end].copy()\n",
    "            yield activity, segment\n",
    "\n",
    "def compute_time_features(window: pd.DataFrame) -> dict:\n",
    "    feats = {}\n",
    "    for col in SENSOR_COLUMNS:\n",
    "        series = window[col].to_numpy()\n",
    "        feats[f\"{col}_mean\"] = float(series.mean())\n",
    "        feats[f\"{col}_std\"] = float(series.std(ddof=1))\n",
    "        feats[f\"{col}_var\"] = float(series.var(ddof=1))\n",
    "    sma = window[ACC_COLUMNS].abs().to_numpy().sum() / len(window)\n",
    "    feats[\"acc_sma\"] = float(sma)\n",
    "    corr_pairs = [(\"acc_x\", \"acc_y\"), (\"acc_x\", \"acc_z\"), (\"acc_y\", \"acc_z\")]\n",
    "    for left, right in corr_pairs:\n",
    "        corr_value = window[left].corr(window[right])\n",
    "        feats[f\"{left}_{right}_corr\"] = float(corr_value) if not np.isnan(corr_value) else 0.0\n",
    "    feats[\"acc_magnitude_mean\"] = float(np.linalg.norm(window[ACC_COLUMNS], axis=1).mean())\n",
    "    feats[\"gyro_magnitude_mean\"] = float(np.linalg.norm(window[GYRO_COLUMNS], axis=1).mean())\n",
    "    return feats\n",
    "\n",
    "def compute_frequency_features(window: pd.DataFrame, sampling_rate_hz: float) -> dict:\n",
    "    feats = {}\n",
    "    n = len(window)\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Each window must contain at least two samples for FFT features.\")\n",
    "    sample_spacing = 1.0 / sampling_rate_hz\n",
    "    freqs = rfftfreq(n, d=sample_spacing)\n",
    "    for col in SENSOR_COLUMNS:\n",
    "        signal = window[col].to_numpy()\n",
    "        demeaned = signal - signal.mean()\n",
    "        spectrum = rfft(demeaned)\n",
    "        magnitudes = np.abs(spectrum)\n",
    "        if len(magnitudes) > 1:\n",
    "            dominant_index = int(np.argmax(magnitudes[1:]) + 1)\n",
    "            dominant_frequency = float(freqs[dominant_index])\n",
    "        else:\n",
    "            dominant_frequency = 0.0\n",
    "        spectral_energy = float(np.sum(magnitudes ** 2) / n)\n",
    "        feats[f\"{col}_dom_freq\"] = dominant_frequency\n",
    "        feats[f\"{col}_spectral_energy\"] = spectral_energy\n",
    "    return feats\n",
    "\n",
    "def extract_features(df: pd.DataFrame, window_seconds: float, overlap: float) -> pd.DataFrame:\n",
    "    sampling_rate_hz = compute_sampling_rate_hz(df['time_acc'])\n",
    "    rows = []\n",
    "    for activity, window in generate_windows(df, sampling_rate_hz, window_seconds, overlap):\n",
    "        rec = {\n",
    "            'activity': activity,\n",
    "            'window_start_time': float(window['time_acc'].iloc[0]),\n",
    "            'window_end_time': float(window['time_acc'].iloc[-1]),\n",
    "            'samples_in_window': len(window),\n",
    "            'window_duration_s': float(len(window) / sampling_rate_hz),\n",
    "        }\n",
    "        rec.update(compute_time_features(window))\n",
    "        rec.update(compute_frequency_features(window, sampling_rate_hz))\n",
    "        rows.append(rec)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7e75f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test data from: testdata\\test_data.csv\n",
      "Activities present:\n",
      "activity\n",
      "being_still    1116\n",
      "jumping        1102\n",
      "standing        745\n",
      "walking         669\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned dataset (prefer testdata/test_data.csv, else cleaned_data.csv)\n",
    "from pathlib import Path\n",
    "\n",
    "candidates = [\n",
    "    Path('testdata') / 'test_data.csv',\n",
    "    Path('cleaned_data.csv'),\n",
    "]\n",
    "\n",
    "data_path = next((p for p in candidates if p.exists()), None)\n",
    "if data_path is None:\n",
    "    print(\"No cleaned CSV found. Expected testdata/test_data.csv or cleaned_data.csv. Setting empty test_df.\")\n",
    "    test_df = pd.DataFrame()\n",
    "else:\n",
    "    print(f\"Using test data from: {data_path}\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    # Expected columns: time_acc, acc_x, acc_y, acc_z, gyro_x, gyro_y, gyro_z, activity\n",
    "    expected_cols = {'time_acc','acc_x','acc_y','acc_z','gyro_x','gyro_y','gyro_z','activity'}\n",
    "    missing = expected_cols - set(df.columns)\n",
    "    if missing:\n",
    "        print(f\"Warning: Missing expected columns in {data_path.name}: {sorted(missing)}. Test set may be unusable.\")\n",
    "    # Normalize activity labels and filter to STATES from the trained model\n",
    "    if 'activity' in df.columns:\n",
    "        df['activity'] = df['activity'].apply(normalize_activity)\n",
    "        df = df[df['activity'].isin(STATES)].copy()\n",
    "    # Ensure numeric types for sensor/time columns\n",
    "    for col in ['time_acc','acc_x','acc_y','acc_z','gyro_x','gyro_y','gyro_z']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df = df.dropna(subset=['time_acc'])\n",
    "    # Sort by time and reset index\n",
    "    test_df = df.sort_values('time_acc').reset_index(drop=True)\n",
    "    # Quick summary\n",
    "    if not test_df.empty and 'activity' in test_df.columns:\n",
    "        print(\"Activities present:\")\n",
    "        print(test_df['activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e9284b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 27 windows from test data.\n",
      "activity\n",
      "being_still    9\n",
      "jumping        9\n",
      "standing       5\n",
      "walking        4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>window_start_time</th>\n",
       "      <th>window_end_time</th>\n",
       "      <th>samples_in_window</th>\n",
       "      <th>window_duration_s</th>\n",
       "      <th>acc_x_mean</th>\n",
       "      <th>acc_x_std</th>\n",
       "      <th>acc_x_var</th>\n",
       "      <th>acc_y_mean</th>\n",
       "      <th>acc_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>acc_y_dom_freq</th>\n",
       "      <th>acc_y_spectral_energy</th>\n",
       "      <th>acc_z_dom_freq</th>\n",
       "      <th>acc_z_spectral_energy</th>\n",
       "      <th>gyro_x_dom_freq</th>\n",
       "      <th>gyro_x_spectral_energy</th>\n",
       "      <th>gyro_y_dom_freq</th>\n",
       "      <th>gyro_y_spectral_energy</th>\n",
       "      <th>gyro_z_dom_freq</th>\n",
       "      <th>gyro_z_spectral_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walking</td>\n",
       "      <td>0.073426</td>\n",
       "      <td>3.534859</td>\n",
       "      <td>346</td>\n",
       "      <td>0.99872</td>\n",
       "      <td>0.573608</td>\n",
       "      <td>1.649239</td>\n",
       "      <td>2.719989</td>\n",
       "      <td>0.639106</td>\n",
       "      <td>2.531528</td>\n",
       "      <td>...</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>1106.690555</td>\n",
       "      <td>7.008970</td>\n",
       "      <td>1180.026559</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>96.783234</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>157.932726</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>496.524599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walking</td>\n",
       "      <td>0.938666</td>\n",
       "      <td>4.400097</td>\n",
       "      <td>346</td>\n",
       "      <td>0.99872</td>\n",
       "      <td>0.479255</td>\n",
       "      <td>1.864960</td>\n",
       "      <td>3.478077</td>\n",
       "      <td>0.456438</td>\n",
       "      <td>2.531758</td>\n",
       "      <td>...</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>1119.774272</td>\n",
       "      <td>7.008970</td>\n",
       "      <td>1337.681334</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>102.108669</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>161.441119</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>478.540163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walking</td>\n",
       "      <td>1.803906</td>\n",
       "      <td>5.265337</td>\n",
       "      <td>346</td>\n",
       "      <td>0.99872</td>\n",
       "      <td>0.293886</td>\n",
       "      <td>1.910185</td>\n",
       "      <td>3.648808</td>\n",
       "      <td>0.436314</td>\n",
       "      <td>2.545961</td>\n",
       "      <td>...</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>1133.375428</td>\n",
       "      <td>7.008970</td>\n",
       "      <td>1212.870721</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>94.899141</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>163.331555</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>419.024820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walking</td>\n",
       "      <td>2.669148</td>\n",
       "      <td>6.130578</td>\n",
       "      <td>346</td>\n",
       "      <td>0.99872</td>\n",
       "      <td>0.020809</td>\n",
       "      <td>1.938420</td>\n",
       "      <td>3.757474</td>\n",
       "      <td>0.466903</td>\n",
       "      <td>2.479065</td>\n",
       "      <td>...</td>\n",
       "      <td>170.217842</td>\n",
       "      <td>1084.718230</td>\n",
       "      <td>6.007689</td>\n",
       "      <td>1236.699251</td>\n",
       "      <td>169.216561</td>\n",
       "      <td>106.742887</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>147.868693</td>\n",
       "      <td>173.221687</td>\n",
       "      <td>363.567621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standing</td>\n",
       "      <td>0.084621</td>\n",
       "      <td>3.553686</td>\n",
       "      <td>346</td>\n",
       "      <td>0.99872</td>\n",
       "      <td>0.049771</td>\n",
       "      <td>0.244237</td>\n",
       "      <td>0.059652</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.165846</td>\n",
       "      <td>...</td>\n",
       "      <td>161.206309</td>\n",
       "      <td>4.752761</td>\n",
       "      <td>160.205028</td>\n",
       "      <td>40.667051</td>\n",
       "      <td>160.205028</td>\n",
       "      <td>1.800030</td>\n",
       "      <td>160.205028</td>\n",
       "      <td>2.065773</td>\n",
       "      <td>2.002563</td>\n",
       "      <td>1.925089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity  window_start_time  window_end_time  samples_in_window  \\\n",
       "0   walking           0.073426         3.534859                346   \n",
       "1   walking           0.938666         4.400097                346   \n",
       "2   walking           1.803906         5.265337                346   \n",
       "3   walking           2.669148         6.130578                346   \n",
       "4  standing           0.084621         3.553686                346   \n",
       "\n",
       "   window_duration_s  acc_x_mean  acc_x_std  acc_x_var  acc_y_mean  acc_y_std  \\\n",
       "0            0.99872    0.573608   1.649239   2.719989    0.639106   2.531528   \n",
       "1            0.99872    0.479255   1.864960   3.478077    0.456438   2.531758   \n",
       "2            0.99872    0.293886   1.910185   3.648808    0.436314   2.545961   \n",
       "3            0.99872    0.020809   1.938420   3.757474    0.466903   2.479065   \n",
       "4            0.99872    0.049771   0.244237   0.059652    0.003244   0.165846   \n",
       "\n",
       "   ...  acc_y_dom_freq  acc_y_spectral_energy  acc_z_dom_freq  \\\n",
       "0  ...      170.217842            1106.690555        7.008970   \n",
       "1  ...      170.217842            1119.774272        7.008970   \n",
       "2  ...      170.217842            1133.375428        7.008970   \n",
       "3  ...      170.217842            1084.718230        6.007689   \n",
       "4  ...      161.206309               4.752761      160.205028   \n",
       "\n",
       "   acc_z_spectral_energy  gyro_x_dom_freq  gyro_x_spectral_energy  \\\n",
       "0            1180.026559       170.217842               96.783234   \n",
       "1            1337.681334       170.217842              102.108669   \n",
       "2            1212.870721       170.217842               94.899141   \n",
       "3            1236.699251       169.216561              106.742887   \n",
       "4              40.667051       160.205028                1.800030   \n",
       "\n",
       "   gyro_y_dom_freq  gyro_y_spectral_energy  gyro_z_dom_freq  \\\n",
       "0       173.221687              157.932726       173.221687   \n",
       "1       173.221687              161.441119       173.221687   \n",
       "2       173.221687              163.331555       173.221687   \n",
       "3       173.221687              147.868693       173.221687   \n",
       "4       160.205028                2.065773         2.002563   \n",
       "\n",
       "   gyro_z_spectral_energy  \n",
       "0              496.524599  \n",
       "1              478.540163  \n",
       "2              419.024820  \n",
       "3              363.567621  \n",
       "4                1.925089  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features on test set\n",
    "if test_df.empty:\n",
    "    print(\"Test dataframe is empty after loading; nothing to evaluate.\")\n",
    "    features_test = pd.DataFrame()\n",
    "else:\n",
    "    # We will use default window params from training bundle\n",
    "    features_test = extract_features(test_df.sort_values('time_acc').reset_index(drop=True),\n",
    "                                     window_seconds=window_seconds_default,\n",
    "                                     overlap=overlap_default)\n",
    "    print(f\"Extracted {len(features_test)} windows from test data.\")\n",
    "    print(features_test['activity'].value_counts())\n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91fc5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted first 20: ['walking', 'walking', 'walking', 'walking', 'standing', 'being_still', 'standing', 'being_still', 'standing', 'being_still', 'being_still', 'being_still', 'being_still', 'standing', 'being_still', 'standing', 'being_still', 'standing', 'jumping', 'jumping']\n",
      "\n",
      "Per-class metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>NumSamples</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>being_still</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jumping</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standing</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walking</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         State  NumSamples  Sensitivity  Specificity\n",
       "0  being_still           9     0.666667     0.888889\n",
       "1      jumping           9     0.333333     1.000000\n",
       "2     standing           5     0.600000     0.863636\n",
       "3      walking           4     1.000000     0.739130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.593\n"
     ]
    }
   ],
   "source": [
    "# Prepare X_test and y_test using the training feature columns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "if features_test.empty:\n",
    "    print(\"No features to evaluate.\")\n",
    "    y_true_idx = np.array([], dtype=int)\n",
    "    y_pred_idx = np.array([], dtype=int)\n",
    "else:\n",
    "    # Align feature columns with training set (drop extras, fill missing with zeros)\n",
    "    feat_cols = [c for c in FEATURE_COLS_TRAIN if c in features_test.columns]\n",
    "    missing_cols = [c for c in FEATURE_COLS_TRAIN if c not in features_test.columns]\n",
    "    if missing_cols:\n",
    "        print(\"Warning: missing feature columns in test set; filling zeros:\", missing_cols)\n",
    "        for c in missing_cols:\n",
    "            features_test[c] = 0.0\n",
    "        feat_cols = FEATURE_COLS_TRAIN\n",
    "    X_test_raw = features_test[feat_cols].values\n",
    "    y_true_idx = features_test['activity'].map(STATE_TO_IDX).values\n",
    "    # Apply scaler and PCA (if present)\n",
    "    X_test_scaled = scaler.transform(X_test_raw)\n",
    "    if pca is not None:\n",
    "        X_test_scaled = pca.transform(X_test_scaled)\n",
    "    # Predict state indices\n",
    "    y_pred_idx = hmm.predict(X_test_scaled)\n",
    "    print(\"Predicted first 20:\", [IDX_TO_STATE[i] for i in y_pred_idx[:20]])\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, labels: list):\n",
    "    if len(y_true) == 0:\n",
    "        # Always return a tuple (DataFrame, overall_accuracy)\n",
    "        empty_df = pd.DataFrame(columns=['State','NumSamples','Sensitivity','Specificity'])\n",
    "        return empty_df, np.nan\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n",
    "    # cm[i,i] = TP for class i\n",
    "    metrics = []\n",
    "    total = cm.sum()\n",
    "    for i, state in enumerate(labels):\n",
    "        TP = cm[i,i]\n",
    "        FN = cm[i,:].sum() - TP\n",
    "        FP = cm[:,i].sum() - TP\n",
    "        TN = total - TP - FN - FP\n",
    "        sens = TP / (TP + FN) if (TP + FN) > 0 else np.nan\n",
    "        spec = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
    "        support = TP + FN\n",
    "        metrics.append({'State': state, 'NumSamples': int(support), 'Sensitivity': sens, 'Specificity': spec})\n",
    "    acc = (y_true == y_pred).mean() if len(y_true) else np.nan\n",
    "    return pd.DataFrame(metrics), acc\n",
    "\n",
    "metrics_df, overall_acc = compute_metrics(y_true_idx, y_pred_idx, STATES)\n",
    "print(\"\\nPer-class metrics:\")\n",
    "display(metrics_df)\n",
    "print(f\"\\nOverall Accuracy: {overall_acc:.3f}\" if not np.isnan(overall_acc) else \"Overall Accuracy: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "662a52b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-class metrics to artifacts\\unseen_eval_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State (Activity)</th>\n",
       "      <th>Number of Samples</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>being_still</td>\n",
       "      <td>9</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jumping</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standing</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walking</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State (Activity)  Number of Samples  Sensitivity  Specificity  \\\n",
       "0      being_still                  9        0.667        0.889   \n",
       "1          jumping                  9        0.333        1.000   \n",
       "2         standing                  5        0.600        0.864   \n",
       "3          walking                  4        1.000        0.739   \n",
       "\n",
       "   Overall Accuracy  \n",
       "0             0.593  \n",
       "1             0.593  \n",
       "2             0.593  \n",
       "3             0.593  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save metrics table for the report and a formatted version matching the assignment table\n",
    "out_dir = Path('artifacts')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "metrics_path = out_dir / 'unseen_eval_metrics.csv'\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "print(f\"Saved per-class metrics to {metrics_path}\")\n",
    "\n",
    "# Create assignment-style table\n",
    "assign_table = metrics_df.copy()\n",
    "assign_table.rename(columns={'State':'State (Activity)','NumSamples':'Number of Samples'}, inplace=True)\n",
    "assign_table['Sensitivity'] = assign_table['Sensitivity'].round(3)\n",
    "assign_table['Specificity'] = assign_table['Specificity'].round(3)\n",
    "assign_table['Overall Accuracy'] = overall_acc if 'overall_acc' in locals() and not np.isnan(overall_acc) else np.nan\n",
    "assign_table['Overall Accuracy'] = assign_table['Overall Accuracy'].round(3) if not assign_table['Overall Accuracy'].isna().all() else assign_table['Overall Accuracy']\n",
    "display(assign_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
